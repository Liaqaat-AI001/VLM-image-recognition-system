# VLM-image-recognition-system

This project is a demo system using a Vision-Language Model (VLM) to identify potential safety hazards in images of industrial or workplace environments. The system analyzes images, generates a JSON summary of safety issues, and displays the results on a user-friendly web interface.

---

## ğŸš€ Features

- âœ… Vision-Language Model (Ovis2-4B) for multi-modal reasoning
- ğŸ§  Prompt-engineered for hazard detection and personnel assessment
- ğŸ”¥ Detects smoke, fire, gear violations, structural damage, and risky behavior
- ğŸ‘· Classifies "environment" and "personnel" safety independently
- ğŸ§¾ Outputs structured JSON (alerts, issues, risk conditions)
- ğŸ–¼ Frontend displays image + inference neatly
- âš™ï¸ CLI-based batch uploader (`batch.py`) to analyze multiple images
- ğŸ’¡ Designed for expansion into real-time camera feeds or dashboards

---

## To use the code we have to follow the following pattern 

## Required Dependencies
python 3.10
Flask
torch 2.3.1 
transformers
Pillow
## Folder Setup
Ensure the project folder has the following structure:
and put the following files in the folders accordingly.
VLM-image-recognition-system/
â”œâ”€â”€ app.py

â”œâ”€â”€ batch.py

â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html

â”œâ”€â”€ static/
â”‚   â””â”€â”€ images/           â† System saves analyzed images here

â”œâ”€â”€ temp_uploads/         â† Uploads are temporarily stored here

â”œâ”€â”€ test_images/          â† You place your test images here

â”œâ”€â”€ uploaded_images/      




